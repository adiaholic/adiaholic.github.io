<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<style type=text/css>body{font-family:monospace;}</style>
	<title>OCR is cool</title>
	
	
	<link rel="stylesheet" href="/adiaholic.github.io/css/style.css">
	
	
</head>
<body>
	<header>
	===============<br>
	== <a href="adiaholic.github.io">Techniche</a> ==<br>
	===============
	<div style="float: right;">Unveiling the Nexus of Tech and Self-Reflection</div><br>
	<p>
	<nav>
			<a href="/"><b>Start</b></a>.
			
</header>

	
	<main>
		<article>
			<h1>OCR is cool</h1>
			<b><time>10.01.2024 10:51</time></b>
		       

			<div>
				<h1 id="ocr">OCR</h1>
<p>I have worked on a project to develop an OCR (Optical Character Recognition) solution using Swift and the Vision framework. The main.swift file contains the core code for performing text recognition in images, utilizing the VNRecognizeTextRequest class provided by Apple&rsquo;s Vision framework. This project aims to provide a straightforward and efficient OCR solution for Swift developers, leveraging the power of machine learning and computer vision technologies.</p>
<p>I have this executable called SwiftOCR-Vision which can be used to extract texts from images and get it&rsquo;s box data.</p>
<p>Github: <a href="https://github.com/adiaholic/SwiftOCR-Vision">https://github.com/adiaholic/SwiftOCR-Vision</a></p>
<p>To build this project I researched a lot of other libraries and framework and below is an overview of some of the stuff I tried.</p>
<h3 id="text-recognition-with-tesseract-hugging-faces-candle-and-apple-vision-kit">Text Recognition with Tesseract, Hugging Face&rsquo;s Candle, and Apple Vision Kit</h3>
<p>In this blog, we will explore text recognition using Tesseract in Python, Hugging Face&rsquo;s Candle in Rust, and Apple&rsquo;s Vision Kit in Swift. We&rsquo;ll cover the basics of each approach and provide code examples for implementing text recognition in these languages.</p>
<h3 id="text-recognition-with-tesseract-in-python">Text Recognition with Tesseract in Python</h3>
<p>Tesseract is a popular open-source OCR (Optical Character Recognition) engine that supports over 100 languages. In Python, you can use the <code>pytesseract</code> library to interface with Tesseract and perform text recognition on images.</p>
<p>Here&rsquo;s a simple example of using Tesseract in Python:</p>
<pre tabindex="0"><code>python
import pytesseract
from PIL import Image
Load an image using PIL
image = Image.open(&#39;image.jpg&#39;)
Perform text recognition using Tesseract
text = pytesseract.image_to_string(image)
Print the recognized text
print(text)
</code></pre><h3 id="text-recognition-with-hugging-faces-candle-in-rust">Text Recognition with Hugging Face&rsquo;s Candle in Rust</h3>
<p>Hugging Face&rsquo;s Candle is a Rust library for natural language processing tasks, including text recognition. It provides a high-level interface for using pre-trained models and performing text recognition tasks in Rust.</p>
<p>Here&rsquo;s a basic example of using Candle for text recognition in Rust:</p>
<pre tabindex="0"><code>rust
use candle::text_recognition;

fn main() {
let image_path = &#34;image.jpg&#34;;
let recognized_text = text_recognition::recognize_text(image_path);
println!(&#34;{}&#34;, recognized_text);
}
</code></pre><h3 id="text-recognition-with-apple-vision-kit-in-swift">Text Recognition with Apple Vision Kit in Swift</h3>
<p>Apple&rsquo;s Vision Kit provides classes and APIs for performing image analysis and computer vision tasks, including text recognition. In Swift, you can use Vision Kit to recognize text in images captured using the device&rsquo;s camera or loaded from the device&rsquo;s storage.</p>
<p>Here&rsquo;s a simple example of using Vision Kit for text recognition in Swift:</p>
<pre tabindex="0"><code>swift
import Vision
import UIKit

func recognizeText(in image: UIImage) {
guard let cgImage = image.cgImage else { return }

let request = VNRecognizeTextRequest { request, error in
guard let observations = request.results as? [VNRecognizedTextObservation] else { return }
for observation in observations {
let recognizedText = observation.topCandidates(1).first?.string ?? &#34;&#34;
print(recognizedText)
}
}

let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
do {
try handler.perform([request])
} catch {
print(error)
}
}

// Usage
let image = UIImage(named: &#34;image.jpg&#34;)!
recognizeText(in: image)
</code></pre><p>By following the examples provided in this blog, you can start performing text recognition using Tesseract in Python, Hugging Face&rsquo;s Candle in Rust, and Apple&rsquo;s Vision Kit in Swift. Each approach has its own strengths and use cases, so choose the one that best fits your requirements.</p>

			</div>
		</article>
	</main>
<aside>
	<div>
		<div>
			<h3>LATEST POSTS</h3>
		</div>
		<div>
			<ul>
				
				<li><a href="adiaholic.github.io/posts/post-three/">Concurrency and Parallelism using Rust</a></li>
				
				<li><a href="adiaholic.github.io/posts/post-two/">OCR is cool</a></li>
				
				<li><a href="adiaholic.github.io/posts/post-one/">Fun with Rust</a></li>
				
			</ul>
		</div>
	</div>
</aside>


	<footer>
	<p>
	<a href="https://github.com/adiaholic"><b>Github</b></a>
	<a href="https://www.linkedin.com/in/adityaborikar/"><b>Linkedin</b></a>
	</p>
	<p>
	&copy; 2024 <b>Aditya Borikar</b>
	</p>
</footer>

</body>
</html>
